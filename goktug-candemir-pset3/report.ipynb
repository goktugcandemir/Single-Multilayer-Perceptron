{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PART I: Theory Questions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q1)<h4>\n",
    "<img src=\"images/q1.jpeg\" style=\"width:600px;height:600\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q2)<h4>\n",
    "    <img src=\"images/q2.jpeg\" style=\"width:600px;height:600\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q3)<h4>\n",
    "<img src=\"images/q3.png\"><br>\n",
    "<p>Specify an advantage of network in the left over one in the right. Explain\n",
    "your answer.</p><br>\n",
    "    <li> We can interpret and input the output as well since the outputs are the weighted sum of inputs<li>As it is less complex and contains less weight than multilayer networks, it can be trained faster.<li>Gives successful results for some  linearly separable functions when adequately trained.<br>\n",
    "    \n",
    "<p>Specify an advantage of network in the right over one in the left. Explain\n",
    "your answer.</p><br>\n",
    "    <li> A single-layer neural network can represent only a limited set of functions. With a multi-layer network, We can represent more complex the functions that the single-layer neural network cannot represent.<br> <li>Since it is more complex, it is longer to train but offers a better chance of learning. <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q4)<h4>\n",
    "    <img src=\"images/q4.jpeg\" style=\"width:600px;height:600\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q5) Fill the blanks with T (True) or F (False) for the statements below:<h4>\n",
    "<li>\n",
    "In every condition, a perceptron network perfectly learns a linearly separable\n",
    "function through a finite number of training steps. (T)</li>\n",
    "  <p>Explanation: Yes , a perceptron can learns a linearly separable functions after adequate training .</p>  <br>\n",
    "<li> Single perceptron can compute the XOR function. (F) </li>\n",
    "<p>Explanation: XOR function is not a linear seperable . So single perceptron can not compute this function.</p>\n",
    "<br><li> In backpropagation learning, the model should start with a small learning\n",
    "parameter and slowly increase it while it is in the learning process. (F)</li>\n",
    "    <p>Explanation : Learning rate must be stay same along the all process</p>\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PART II: Classification of Natural Scenes using Neural Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, I will create an artificial neural network a single layer, and multilayer neural network architecture to classify natural scenes around the world into 6 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data Preprocessing</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I resized the given image size to 30x30 and convert it to gray images. After all this process I got a [900 x 1] vector and related label. After that, I used normalization operation to restrict the vector between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Artificial Neural Network Model </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, I did not create separate models for single and multilayer neural networks. In the model I created, we can determine the number of hidden layers we want to set as parameters.The Parameter type that determines the number of hidden layers in the network will be the list. If you are going to create a single layer, the parameter will be empty list ([ ]). If you give the number of hidden layers as an empty list, the model works as a single layer. For example, if we give the parameter as [10,8], we will create a multilayer neural network with the first hidden layer 10 neuron and the second hidden layer 8 neuron.\n",
    "<h4>Artificial Neural Network Initialization</h4>\n",
    "<br>\n",
    "<img src=\"images/init.png\"><br>\n",
    "In the model we created, I created weights, activations, and derivatives activities, and  I initialized activations and derivations with 0 and weights with random numbers between -1 and 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Single Layer Neural Network</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gave the hidden layer parameter of the model that we created for the single-layer network as an empty list and created our single-layer network. Since the vector we obtained from our data is a 900x1 vector, the input layer in our network is 900, and the output layer is 6 because we have 6 classes in total. The code I wrote for this is ann = ArtificialNeuralNetwork (900, [], 6) . After creating the model I trained the model to learn classification operations. To ensure adequate learning, I set the epoch value to 1000 and the batch size value to 1 which is Stochastic. I used the means square error function as the loss function. The mean squared error and epoch graph is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/single1.png\">\n",
    "<img src=\"images/single2.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the graph, the more epoch number, the better the accuracy of the train, but it takes much more time to train. As can be seen from the 1000 epoch graph, the error reduction is very slow after a certain epoch. The learning rate used here is also important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Activation Functions</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used different activation functions in this assignment. The activation functions I use are: RELU, Sigmoid, tanh and softmax. I used the softmax activation function only for the output layer. The selected activation functions affect the successful classification result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experiments, I saw some weaknesses of the sigmoid and tanh function. When the x value is small or big the slope is zero then there is no learning . To avoid this situation, I normalized the image we got. So after fix this problem I chose to use tanh activation function for the hidden layers and softmax function for the output layers. Both activation functions (tanh and sigmoid) resulted close to each other.\n",
    "<img src=\"images/tanh.png\"><br>\n",
    "<img src=\"images/sigmoid.png\"><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Batch Size</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batchsize value is an important hyperparameter as it affects the number of backpropagations to be made during the train. The higher the batchsize value, the less backpropagaiton will be done, so the train process takes much less time. Because the backpropagation process is a costly and time consuming process.\n",
    "<br>\n",
    "<img src=\"images/single-batch.png\"><br>\n",
    "However, as can be seen from the graph, the higher the batch size, the worse the learning rate of the model with the same number of epochs. Therefore, the model is likely to learn worse when the batch size is increased. Therefore, it is necessary to balance well in the selection of batch size, while saving time and process cost, we lose learning skills.<br> In addition, I have plotted the results obtained with different batchsize values as follows.<br>\n",
    "<img src=\"images/single-batch-all.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Loss Function</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used mean square error as the loss function because it is easy to understand and the derivative process is easy to use.I used mean square error as the loss function because it is easy to understand and the derivative process is easy to use. I also used the cross entropy loss function, but the mean squarer error function is used in the final code.\n",
    "\n",
    "<h4>Activation Function</h4><br>\n",
    "In my experiments, I saw some weaknesses of the sigmoid function. When the x value is small or big the slope is zero then there is no learning . To avoid this situation, I normalized the image we got. So after fix this problem I chose to use sigmoid activation function for the hidden layers and softmax function for the output layers. In my experiments,  tanh activation function gives better results for single layer, sigmoid function for multi layer gives better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Accuracy-Learning Rate</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we directly use the learning rate value given in the backpropagation stage, the determined learning rate directly affects learning. High learning rate will cause oscillation. On the other hand, being small will cause the learning to take too long as it will progress with small steps. Therefore, learning rate is a hyperparameter that is important to choose the optimum value and directly affects the result.<br> \n",
    "<img src=\"images/single-accuracy.png\"><br> Here we can see how the learning rate value affects the accuracy, and we see from the bar chart that the most optimal learning rate value for a single layer is 0.01. As a result of the training, I got 33-38% accuracy in single layer neural network.<br>\n",
    "<img src=\"images/accuracy-learningrate.png\"><br>\n",
    "<h4>Accuracy - Epoch</h4>\n",
    "<img src=\"images/accuracy.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multi Layer Neural Network</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference of multilayer neural network from single is hidden layer between input and output layer. In the structure we have created, we can create as many hidden layers as we want, including any number of neuron. When we add a hidden layer, the complexity of the network increases, but it also enables us to solve problems that are not linearly seperable that we cannot solve with a single layer. Since we add hidden layers in the multilayer neural network, the number of weights to be learned increases and this causes the train operations to take much longer. That's why we can say that single layer is faster train. However, I achieved a much more successful accuracy score for multilayer neural network than single layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Accuracy-Learning Rate</h4> <br>\n",
    "Learning rate value is an important hyperparameter. The graph I created by training the model with different learning rate values and taking the loss values from the loss function to see which learning rate gives better results for our model is as follows.<br>\n",
    "<img src=\"images/multilayer-learningrate.png\"><br>\n",
    "As can be understood from the graph, learning rate has a significant effect on the result. We see in the graph that the most optimal learning rate is 0.03. Therefore, I took the learning rate value as 0.03 in all the following operations.\n",
    "\n",
    "<br>\n",
    "As a result of the training, I got 38-47% accuracy in multi layer neural network.\n",
    "<img src=\"images/multilayer_accuracy.png\"><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Batchsize Effect</h4><br>\n",
    "The same situation we mentioned in the single layer is also valid here. As the batch size increases, the back propagation process decreases, the train process is much faster, but the model  learns less and accuracy lower than the Stochastic (batchsize = 1). We know that error and accuracy are inversely proportional.\n",
    "<img src=\"images/multilayer-batchsize.png\"><br>\n",
    "However, if a batch size equal to one, increases the process cost and the time taken for the train, so determining the ideal batchsize value is important and directly affects the result.\n",
    "<h4>Error Function</h4><br>\n",
    "I used mean square error as the loss function because it is easy to understand and the derivative process is easy to use.I used mean square error as the loss function because it is easy to understand and the derivative process is easy to use. I also used the cross entropy loss function, but the mean squarer error function is used in the final code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Layers and # Neuron Effect</h4><br>\n",
    "The number of hidden layers created in the multilayer neural network created and the number of neurons they have are also important factors affecting the result. As the number of neuron increases, the number of weights to be calculated increases and therefore the cost of both the forward pass and the backpropagation process increases. However, the increasing number of neurons and layers generally has an enhancing effect on learning. In short, while increasing the number of neurons and the number of hidden layers increases the cost of the procedure and the time taken to train. Therefore, ideal hidden layers and neuron should be used. The idea that constantly increasing the number of hidden layers will result in better learning is not always correct. Therefore, it is better to find the ideal number of hidden layers and use it.\n",
    "<img src=\"images/multilayer-layers.png\"><br>\n",
    "The graph below shows the accuracy values of the models with different numbers of hidden layers.\n",
    "\n",
    "<img src=\"images/multilayeraccuracy.png\"><br>\n",
    "<img src=\"images/multilayer_accuracy.png\"><br>\n",
    "<img src=\"images/4hidenlayerAccuracy.png\"><br>\n",
    "\n",
    "\n",
    "As can be seen from the graph, I saw that when I increased the number of layers and the number of neurons in the layers, the accuracy result increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Class Weights Visualization</h3><br>\n",
    "<b>Buildings : <img src=\"images/buildings.png\" style=\"width:150px;height:150\"><br>\n",
    "<b>Forest : <img src=\"images/forest.png\"style=\"width:150px;height:150\"><br>\n",
    "Glacier : <img src=\"images/glacier.png\"style=\"width:150px;height:150\"><br>\n",
    "Mountain :  <img src=\"images/mountain.png\"style=\"width:150px;height:150\"><br>\n",
    "Sea : <img src=\"images/sea.png\"style=\"width:150px;height:150\"><br>\n",
    "Street : <img src=\"images/street.png\"style=\"width:150px;height:150\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparison Single-layer and Multi-Layer Neural Network</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can effectively perform functions that are single-layer neural and linearly seperable. However, there are functions that the single layer network cannot solve, such as the XOR function. Many problems in daily life are not linearly seperable. Therefore, a multilayer neural network is usually used. Multilayer neural network takes longer to train and is more costly than single layer network. However, it gives more successful results than single layer network. In order to get the most efficient result, it is necessary to choose the correct hyperparameters such as batchsize, # hidden layers, # neurons, learning rate, etc.<br>Below, the accuracy values obtained by using single layer and multilayer network in 2 separate models trained with the same dataset are shown. It can be seen in the graph that the multilayer network is more successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ml-sl.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Running</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide 3 parameters to run the code. First parameters is model preference. We need to write multilayer for multilayer neural network and singlayer for singlelayer neural network. The second parameter is determining the images to be predict. We need to tell whether it is test data or validation data. We need to write \"test\" for test data and \"validation\" for validation data. The third parameter will be the pathy of the test data. If we want to run it over validation data, we can write something random for this parameter. If we are going to predict over test data, we need to give the path of the test data.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>To run sample code: python assignment3.py multilayer test seg_test<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/run.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Important Note:</b> To successfully read test and validation images while running the code, the images must be in the same directory as the code. To run the code correctly, the python file and the models must be in the same directory.As below picture\n",
    "<img src=\"images/dosya.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
